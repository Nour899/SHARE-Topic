{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f526c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "topic=45\n",
    "batch_size=1000\n",
    "\n",
    "dev = \"cuda:0\"\n",
    "device = torch.device(dev)\n",
    "\n",
    "data_atac=torch.load('/data/nelkazwi/lymphoma_data/atac_lymphoma.txt')\n",
    "theta=torch.load(\"/scratch/nelkazwi/lymphoma_data/\"+str(topic)+\"_topics/theta_\"+str(topic)+\".txt\")\n",
    "phi=torch.load(\"/scratch/nelkazwi/lymphoma_data/\"+str(topic)+\"_topics/phi_\"+str(topic)+\".txt\")\n",
    "theta=theta[50:,:,:]\n",
    "phi=phi[50:,:,:]\n",
    "\n",
    "\n",
    "n_samples=phi.shape[0]\n",
    "n=theta.shape[2]\n",
    "P=data_atac.shape[1]\n",
    "L=torch.zeros(P,dtype=torch.double,device=device)\n",
    "V=torch.zeros(P,device=device)\n",
    "V_2=torch.zeros(P,device=device)\n",
    "n_cells=theta.shape[1]    \n",
    "\n",
    "n_batches=n_cells+batch_size-(n_cells%batch_size)\n",
    "c=torch.arange(0,n_batches,batch_size)\n",
    "c=torch.hstack((c,torch.tensor(n_cells)))\n",
    "c=c.to(device)\n",
    "\n",
    "a,b,rep_c=torch.unique(data_atac[0,:],return_inverse =True,return_counts=True)\n",
    "rep_c=rep_c.type(torch.LongTensor) \n",
    "ren=torch.arange(n_cells)\n",
    "rep_c_=torch.repeat_interleave(ren, rep_c,dim=0)\n",
    "\n",
    "\n",
    "k_atac=torch.zeros(c.shape[0],dtype=torch.int64)\n",
    "\n",
    "q=1\n",
    "t=0\n",
    "t_=0\n",
    "for i in  torch.arange(batch_size,n_batches,batch_size):\n",
    "    \n",
    "    k_atac[q]=t+torch.sum(rep_c[t_:i])\n",
    "    t=int(k_atac[q].item())\n",
    "    t_=i\n",
    "    q+=1\n",
    "k_atac[q]=t+torch.sum(rep_c[t_:])\n",
    "\n",
    "indices=torch.zeros([data_atac.shape[1]])\n",
    "indices2=torch.zeros([data_atac.shape[1]])\n",
    "regions=torch.tensor([])\n",
    "region_rep=torch.tensor([])\n",
    "region_rep_=torch.tensor([])\n",
    "region_batching=torch.zeros([k_atac.shape[0]])\n",
    "for i in torch.arange(1,k_atac.shape[0]):\n",
    "    \n",
    "   sorted, indices[int(k_atac[i-1].item()):int(k_atac[i].item())]= torch.sort(\n",
    "       data_atac[1,int(k_atac[i-1].item()):int(k_atac[i].item())])\n",
    "   sorted2,indices2[int(k_atac[i-1].item()):int(k_atac[i].item())]=torch.sort(\n",
    "       indices[int(k_atac[i-1].item()):int(k_atac[i].item())])\n",
    "   a,b,rep_r=torch.unique(\n",
    "       sorted,return_inverse =True,return_counts=True)\n",
    "   regions=torch.cat((regions,a),0)\n",
    "   region_batching[i]=a.shape[0]+region_batching[i-1] ##list of regiosn per batch\n",
    "   region_rep=torch.cat((region_rep,rep_r),0) ##how many times presented region in a batch are repeated\n",
    "   rep_r=rep_r.type(torch.LongTensor) \n",
    "   ren=torch.arange(a.shape[0]) \n",
    "   rep_r_=torch.repeat_interleave(ren, rep_r,dim=0)\n",
    "   region_rep_=torch.cat((region_rep_,rep_r_),0) \n",
    "\n",
    "region_rep=region_rep.type(torch.LongTensor) \n",
    "regions=regions.type(torch.LongTensor) \n",
    "indices=indices.int()\n",
    "indices2=indices2.int()\n",
    "region_rep_=region_rep_.type(torch.int64)\n",
    "\n",
    "\n",
    "region_rep=region_rep.to(device)\n",
    "regions=regions.to(device)\n",
    "indices=indices.to(device)\n",
    "indices2=indices2.to(device)\n",
    "rep_c=rep_c.to(device)\n",
    "rep_c_=rep_c_.to(device)\n",
    "region_rep_=region_rep_.to(device)\n",
    "\n",
    "\n",
    "for sample in range(0,n_samples):\n",
    "    theta_tmp=theta[sample,:,:].to(device)\n",
    "    phi_tmp=phi[sample,:,:].to(device)\n",
    "    for i in torch.arange(1,c.shape[0]):\n",
    "        theta_=theta_tmp[c[i-1]:c[i],:]\n",
    "        phi_=phi_tmp[:,regions[int(region_batching[i-1].item()):int(region_batching[i].item())]]\n",
    "        n_regions=phi_.shape[1]\n",
    "        z_atac_=torch.repeat_interleave(\n",
    "        theta_, rep_c[c[i-1]:c[i]],dim=0)##cells in this batch\n",
    "        phi_=torch.repeat_interleave(\n",
    "           phi_,region_rep[int(region_batching[i-1].item()):int(region_batching[i].item())],dim=1)##regions in this batch\n",
    "        phi_=torch.index_select(phi_,1, indices2[int(k_atac[i-1].item()):int(k_atac[i].item())])##reorder the regions acording to data\n",
    "        z_atac_=torch.multiply(z_atac_.T,phi_)\n",
    "        \n",
    "        z_atac_=torch.sum(z_atac_,axis=0)\n",
    "        L[int(k_atac[i-1].item()):int(k_atac[i].item())]+=z_atac_\n",
    "        V[int(k_atac[i-1].item()):int(k_atac[i].item())]+=torch.pow(torch.log(z_atac_),2)\n",
    "        V_2[int(k_atac[i-1].item()):int(k_atac[i].item())]+=torch.log(z_atac_)\n",
    "WAIC=-2*(torch.sum(torch.log(L/n_samples))-(torch.sum(V)-torch.sum(torch.pow(V_2,2)/n_samples))/(n_samples-1))\n",
    "torch.save(WAIC,\"/scratch/nelkazwi/lymphoma_data/\"+str(n)+\"_topics/WAIC_r_\"+str(n)+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d81f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
